ğŸ˜¢ Emotion-Aware Training (Text Classification)
Instead of using off-the-shelf sentiment tools, I fine-tuned LLaMA 3.2 (1B) on a curated dataset of emotional dialogues and annotated text. The goal wasnâ€™t just sentiment polarity (positive/negative) but nuanced categories like anger, joy, sadness, fear, disgust, surprise, and neutral.

ğŸ§  Core Model (LLM Backbone)
LLaMA 3.2 serves as the backbone. Its compact 1B parameter size makes it lightweight and efficient for deployment, while fine-tuning aligns it with the task of recognizing subtle emotional cues in sentences. This ensures the model captures both explicit expressions (â€œI am furiousâ€) and implicit signals (â€œI canâ€™t believe this happened againâ€).

ğŸ“Š Data Engineering (Emotion Annotations)
The dataset was engineered to balance real-world dialogues, social media text, and scripted conversations. Each text segment was paired with emotion tags. Heavy preprocessingâ€”like removing noise, normalizing slang, and handling code-switching (English + Hindi)â€”was done to make the model robust in real applications.

âš¡ Pipeline Integration
Training loop: Hugging Face transformers + PEFT/LoRA for efficient fine-tuning.


ğŸš€ End Goal
This wasnâ€™t just about detecting â€œpositive vs. negative,â€ but about teaching an open-source LLM to understand human emotions in textâ€”a key step toward emotionally intelligent conversational agents.
